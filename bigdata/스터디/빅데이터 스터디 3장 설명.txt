사이킷런 설치 -> 파이썬의 대표적인 머신러닝 라이브러리, 머신러닝을 위한 다양한 알고리즘, 프레임워크, api  제공함. 

# 노트북 실행 결과를 동일하게 유지하기 위해
np.random.seed(42)
시드 값 설정 -> 무작위 수를 생성하는 알고리즘에서 사용되는 초기값, 시드값 고정하면 항상 같은 난수 수열이 생성되서 머신러닝 모델 반복실행해도 학습 결과가 항상 동일하게 나옴.(머신러닝의 재현성)

fetch_openml -> 사이킷런 데이터 셋 중 openML 데이터 저장소에서 데이터를 가져옴.
OpenML에서 가져온  사이킷런의 'bunch' 객체로 변환하여 반환
'bunch'객체는 변수명을 속성으로 접근. ex) mnist.data -> 'mnist[data]
 변수명을 속성으로 접근하는 이유?
객체 지향 프로그래밍을 할 때 사용되는 방식. 객체의 속성과 메소드를 하나의 네임스페이스 안에서 관리 가능. -> 코드의 가독성과 유지보수성 향상


mnist 데이터 셋 로드해서 변수 X와  y에 할당함 
mnist["data"]는  mnist 데이터 셋의 픽셀값 데이터, 이미지 데이터를 담고 있는 변수
mnist["target"]는 mnist 데이터셋의 레이블을 나타냄(0~9까지) 
mnist["target"][i]는 i에 해당하는 이미지의 실제 숫자임
mnist["target"][0]가 5라면, mnist["data"][0]에 해당하는 이미지는 손으로 쓴 숫자 5를 나타냅니다. mnist["target"][1]이 0이라면, mnist["data"][1]에 해당하는 이미지는 손으로 쓴 숫자 0을 나타냅니다. 이와 같은 방식으로 각 이미지와 해당하는 정답 숫자(레이블)가 매칭되어 있습니다.


mnist 데이터셋 -> 숫자 이미지 데이터. 각 이미지는 28 * 28 크기의 2차원 어레이, 데이터 셋에서는 각 이미지를 1차원 어레이로 변환하여 저장 
-> 입력 데이터의 차원을 줄이고 모델 학습의 효율성 높임. 하지만 이렇게 하면 공간적인 구조 정보를 완전히 잃어버리게 된다. 

공간적인 구조 정보? - 이미지의 픽셀 배치와 배치 순서 의미, 이미지의 왼쪽 위부터 오른쪽으로 픽셀 값을 나열한 경우, 이미지의 위에서부터 아래로 픽셀 값을 나열한 경우는 공간적인 구조가 다르다.
이미지 처리나 컴퓨터 비전 작업에서 중요한 역할

some_digit_image = some_digit.reshape(28,28) 
mnist 데이터 셋에서 이미지 데이터 : 1차원 어레이 였으므로 다시 이미지의 공간적인 구조 정보 유지하기 위해 reshap() 함수를 이요하여 2차원 어레이로 변환함. 

모델 훈련을 위해 정수형으로 변환하는 이유?
예) 손글씨 숫자 인식 문제에서 출력값은 0부터 9까지의 정수형이며, 분류 문제에서는 각 클래스를 정수형으로 표현하기도 합니다. 이 경우, 모델의 출력값과 정답값이 모두 정수형이기 때문에, 입력값도 정수형으로 변환하여 일관성을 유지하는 것이 좋습니다.

확률적 하강 경사법 
온라인학습 : 실시간으로 업데이트 , 대규모 데이터 처리에 좋음(데이터가 도착하는 즉시 처리)
sgd는 훈련하는데 무작위성을 사용함('확률적')
그래서 결과가 똑같이 나오도록 하려면  random_state를 지정해주어야함
특정 값으로 설정하여 항상 동일한 결과를 얻을 수 있음 항상 동일한 초기화와 난수 생성과정 반복됨.
다른 하이퍼파라미터 조합의 모델을 정확히 비교가능.
동일한 훈련 및 테스트 데이터 분할이 생성되어서 모델의 성능이 일관되게 비교되고 평가 할 수 있다.

확률적 하강 경사법을 할 때 tol=le-3: 전체 훈련 세트를 한 번 학습할 때마다 성능 향상이 연속적으로 지정된 값  이상으로 이루어지지 않을 때 학습을 멈추도록 함
tol 매개 변수를 사용하는 이유
학습 멈추어 불필요한 계산 줄이고 효율적인 학습 하도록
학습시간 단축 -> 불필요한 반복 줄여 성능 향상 별로 없거나 추가적인 반복하면 시간과 계산비용 낭비하는 것. 성능 충분히 달성하면 중지함
과적합 방지 : 모델이 훈련 데이터에 지나치게 적합되어 새로운 데이터에 대한 일반화 능력 저하되는 현상 방지 

오차행렬 : 분류기의 성능을 더 평가하기 위해


교차 검증을 이용한 정확도 측정 문제점
무조건  False 라고 예측하는 분류기를 만들어도 
무조건 5가 아니라고 찍는 분류기도 90%의 정확도를 보여줌.
이미지의 10% 정도만 숫자 5이기 때문에 무조건 ‘5 아님’ 이라고 예측하면 정확히 맞출 확률 -> 90%
불균형한 데이터셋을 다룰때 (어떤 클래스가 다른 것보다 월등히 많은 경우) 분류기의 성능 측정 지표로 선호하지 않는 이유.

정밀도 재현율 그래프에서 정밀도 그래프가 더 울퉁불퉁한 이유
임곗값을 올리더라도 정밀도가 가끔 낮아짐
재현율은 임계값이 올라가면 따라서 줄어드므로 곡선형이 될 수 밖에 없다.

완전한 랜덤분류기? 훈련 데이터 클래스 비율을 따라 무작위로 예측하는 것
오차행렬의 실제 클래스가 비슷한 비율의 예측 클래스로 나뉘어 FPR(거짓 양성 비율) TPR(참 양성 비율) 값이 비슷해짐, ROC 곡선이 y=x에 가깝게 되어 AUC 면적이 0.5

대부분의 이진분류기에서 OvR을 선호하는 이유
클래스 수가 많으면 OvO방식이 비현실적이고 비효율적
OvR은 각 클래스를 다른 모든 클래스와 구분하는 분류기를 훈련시키기 때문에 클래스의 수에 상관없이 분류기의 수는 클래스의 개수와 동일. 클래수 수에 크게 영향받지 않으므로 클래스 수가 많을 때 OvR선호

SGDClassfier : 클래스마다 픽셀에 가중치 할당. 새로운 이미지에 대해 단순히 픽셀 강도의 가중치 합을 클래스의 점수로 계산함

mnist 이미지에서 추출한 훈련세트에 잡음을 추가하여 잡음이 섞인 이미지를 사용하여 잡음 제거 작업을 수행하는 이유?
데이터의 다양성을 높이고 모델을 더 강건하게 만듬, 실제 환경에서의 문제에 대처할 수 있는 능력을 갖추기 위해서