MINIST 데이터셋 받아 이 글자가 어떤 숫자를 의미하는지 알아보는 모데를 만들 것
일단 MNIST 데이터셋을 내려받고, mnist 키를 확인하면 키들이 딕셔너리 형태로 저장된 것을 알 수 있음
그 키 들 중에서 data와 target을 X,y로 할당한다. 피피티 설명
그리고 이미지데이터 2차원 어레이로 변환. 
 mnist 데이터셋 -> 숫자 이미지 데이터. 각 이미지는 28 * 28 크기의 2차원 어레이, 데이터 셋에서는 각 이미지를 1차원 어레이로 변환하여 저장 
-> 입력 데이터의 차원을 줄이고 모델 학습의 효율성 높임. 하지만 이렇게 하면 공간적인 구조 정보를 완전히 잃어버리게 된다. 
그리고 이 나온 사진에 있는 글자가 무엇인지 확인하면 5인걸 확인할 수 있따. (훈련된 데이터가 아닌 이미지의 해당하는 픽셀값과 레이블(타깃값)을 가져온 것임)
모델훈련을 위해 정수형으로 변환함.
변환하는 이유 설명~
훈련하기 위해 훈련데이터와 테스트 데이터셋으로 나눔
일단 이미지가 숫자 5 표현하는지 알 수 있는 이진분류기 훈련을 함 
0이면 숫자 5가 아닌걸로 판별, 1이면 숫자 5인걸로 판별하는 것
sgdclassifier을 사용함 이 분류기는 확률적 경사 하강법을 사용하는데

확률적 하강 경사법 
온라인학습 : 실시간으로 업데이트 , 대규모 데이터 처리에 좋음(데이터가 도착하는 즉시 처리)
sgd는 훈련하는데 무작위성을 사용함('확률적')
그래서 결과가 똑같이 나오도록 하려면  random_state를 지정해주어야함
특정 값으로 설정하여 항상 동일한 결과를 얻을 수 있음 항상 동일한 초기화와 난수 생성과정 반복됨.
다른 하이퍼파라미터 조합의 모델을 정확히 비교가능.
동일한 훈련 및 테스트 데이터 분할이 생성되어서 모델의 성능이 일관되게 비교되고 평가 할 수 있다.

확률적 하강 경사법을 할 때 tol=le-3: 전체 훈련 세트를 한 번 학습할 때마다 성능 향상이 연속적으로 지정된 값  이상으로 이루어지지 않을 때 학습을 멈추도록 함
tol 매개 변수를 사용하는 이유
학습 멈추어 불필요한 계산 줄이고 효율적인 학습 하도록
학습시간 단축 -> 불필요한 반복 줄여 성능 향상 별로 없거나 추가적인 반복하면 시간과 계산비용 낭비하는 것. 성능 충분히 달성하면 중지함
과적합 방지 : 모델이 훈련 데이터에 지나치게 적합되어 새로운 데이터에 대한 일반화 능력 저하되는 현상 방지 

아까 나왔던 숫자 사진을 감지하면 이미지가 5를 나타낸다고 추측하여 잘 훈련된 것을 알 수 있다.
성능 측정
이렇게 함수가 제공하지 않는 기능을 이용하려면 교차 검증을 직접 구현할 수 있음

3겹 교차 검증을 함수를이용하여 실행할 수도 있음 -> 결과 정확도 95퍼 이상임


교차 검증을 이용한 정확도 측정 문제점
불균형한 데이터셋을 다룰때 (어떤 클래스가 다른 것보다 월등히 많은 경우) 분류기의 성능 측정 지표로 선호하지 않는 이유.
무조건 false라고 예측하는 분류기를 만들어서 교차검증 정확도 측정이 괜찮은지 확인가능
이 분류기도 90퍼의 정확도를 보여줘 신뢰성x

오차행렬 : 실제 클래스와 예측된 클래스 조합에 따라 샘플을 분류하고 분류 결과를 볼 수 있음

조화평균: 각 요소의 역수를 산술평균하고 그 값을 또 다시 역수로 변환한 것
산술평균은 a+b /2 


업무의 특성상 정밀도 또는 재현율이 특별히 강조돼야 할 경우가 있는데 이때는 임계값을 조정해 정밀도 또는 재현율을 높일 수 있다. 하지만 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 높이면 다른 한쪽은 줄어들게 된다. 이를 정밀도/재현율의 트레이드 오프


AUC값은 ROC곡선 밑의 면적을 구한 것으로 일반적으로 1에 가까울수록 좋은 수치이고, 0.5에 가까울수록 학습이 제대로 이루어지지 않은 모델


정밀도 재현율 그래프에서 정밀도 그래프가 더 울퉁불퉁한 이유
임곗값을 올리더라도 정밀도가 가끔 낮아짐
재현율은 임계값이 올라가면 따라서 줄어드므로 곡선형이 될 수 밖에 없다.

완전한 랜덤분류기? 훈련 데이터 클래스 비율을 따라 무작위로 예측하는 것
오차행렬의 실제 클래스가 비슷한 비율의 예측 클래스로 나뉘어 FPR(거짓 양성 비율) TPR(참 양성 비율) 값이 비슷해짐, ROC 곡선이 y=x에 가깝게 되어 AUC 면적이 0.5

대부분의 이진분류기에서 OvR을 선호하는 이유
클래스 수가 많으면 OvO방식이 비현실적이고 비효율적
OvR은 각 클래스를 다른 모든 클래스와 구분하는 분류기를 훈련시키기 때문에 클래스의 수에 상관없이 분류기의 수는 클래스의 개수와 동일. 클래수 수에 크게 영향받지 않으므로 클래스 수가 많을 때 OvR선호

SGDClassfier : 클래스마다 픽셀에 가중치 할당. 새로운 이미지에 대해 단순히 픽셀 강도의 가중치 합을 클래스의 점수로 계산함

mnist 이미지에서 추출한 훈련세트에 잡음을 추가하여 잡음이 섞인 이미지를 사용하여 잡음 제거 작업을 수행하는 이유?
데이터의 다양성을 높이고 모델을 더 강건하게 만듬, 실제 환경에서의 문제에 대처할 수 있는 능력을 갖추기 위해서
